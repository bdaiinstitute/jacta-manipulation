:py:mod:`visualizers.viser_app.controllers.sampling.predictive_sampling`
========================================================================

.. py:module:: visualizers.viser_app.controllers.sampling.predictive_sampling


Module Contents
---------------

.. py:class:: PredictiveSamplingConfig


   Bases: :py:obj:`jacta.visualizers.viser_app.controllers.sampling_base.SamplingBaseConfig`

   
   Configuration for predictive sampling.
   .. py:attribute:: sigma
      :type: float
      :value: 0.05

      

   .. py:attribute:: noise_ramp
      :type: float
      :value: 1.0

      


.. py:class:: PredictiveSampling(task: jacta.visualizers.viser_app.tasks.task.Task, config: PredictiveSamplingConfig, reward_config: jacta.visualizers.viser_app.tasks.task.TaskConfig)


   Bases: :py:obj:`jacta.visualizers.viser_app.controllers.sampling_base.SamplingBase`

   
   Predictive sampling planner.

   :param config: configuration object with hyperparameters for planner.
   :param model: mujoco model of system being controlled.
   :param data: current configuration data for mujoco model.
   :param reward_func: function mapping batches of states/controls to batches of rewards.
   .. py:method:: update_action(curr_state: numpy.ndarray, curr_time: float, additional_info: dict[str, Any]) -> None

      
      Performs rollouts + reward computation from current state.

   .. py:method:: action(time: float) -> numpy.ndarray

      
      Current best action of policy.


