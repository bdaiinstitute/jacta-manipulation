:py:mod:`mppi`
==============

.. py:module:: mppi


Module Contents
---------------

.. py:class:: MPPIConfig


   Bases: :py:obj:`dexterity.controllers.sampling_base.SamplingBaseConfig`

   
   Configuration for predictive sampling.
   .. py:attribute:: sigma
      :type: float
      :value: 0.05

      

   .. py:attribute:: temperature
      :type: float
      :value: 1.0

      


.. py:class:: MPPI(task: dexterity.tasks.task.Task, config: MPPIConfig, reward_config: dexterity.tasks.task.TaskConfig)


   Bases: :py:obj:`dexterity.controllers.sampling_base.SamplingBase`

   
   Predictive sampling planner.

   :param config: configuration object with hyperparameters for planner.
   :param model: mujoco model of system being controlled.
   :param data: current configuration data for mujoco model.
   :param reward_func: function mapping batches of states/controls to batches of rewards.
   .. py:method:: update_action(curr_state: numpy.ndarray, curr_time: float, additional_info: dict[str, Any]) -> None

      
      Performs rollouts + reward computation from current state.

   .. py:method:: action(time: float) -> numpy.ndarray

      
      Current best action of policy.


