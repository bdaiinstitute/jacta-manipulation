:py:mod:`tasks.spot_position_control`
=====================================

.. py:module:: tasks.spot_position_control


Module Contents
---------------

.. py:data:: MODEL_PATH
   :value: 'dexterity/models/xml/scenes/legacy/spot_position_control.xml'

   

.. py:class:: SpotPositionControlConfig


   Bases: :py:obj:`dexterity.tasks.task.TaskConfig`

   
   Reward configuration for the Spot simple task
   .. py:attribute:: w_standing
      :type: float
      :value: 100.0

      

   .. py:attribute:: w_forward
      :type: float
      :value: 0.0

      

   .. py:attribute:: w_legs
      :type: float
      :value: 0.0

      

   .. py:attribute:: w_arms
      :type: float
      :value: 1.0

      

   .. py:attribute:: default_command
      :type: Optional[numpy.ndarray]

      


.. py:class:: SpotPositionControl


   Bases: :py:obj:`dexterity.tasks.mujoco_task.MujocoTask`\ [\ :py:obj:`SpotPositionControlConfig`\ ]

   
   Defines the Spot standing up task.
   .. py:method:: reward(states: numpy.ndarray, sensors: numpy.ndarray, controls: numpy.ndarray, config: SpotPositionControlConfig) -> numpy.ndarray

      
      Implements the Spot reward to have it stand up and go to a goal.

      Maps a list of states, a list of control, to a batch of rewards (summed over time) for each rollout.

      Spot has four main reward terms:

      ::

         * `position_rew`, penalizing the distance between the Spot body position and the final position
         * `orientation_rew`, penalizing the distance between the Spot body orientation and the final orientation
         * `leg_rew`, penalizing the difference between Spot leg angles and the final leg angles
         * `arm_rew`, penalizing the difference between the Spot arm angles and the final arm angles

   .. py:method:: reset() -> None

      
      Resets the model to a slightly random state


