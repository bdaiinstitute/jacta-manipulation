:py:mod:`core.graph_worker`
===========================

.. py:module:: core.graph_worker


Module Contents
---------------

.. py:function:: pareto_distribution(length: int, exponent: float) -> torch.FloatTensor


.. py:class:: GraphWorker(plant: jacta.planner.dynamics.simulator_plant.SimulatorPlant, graph: jacta.planner.core.graph.Graph, action_sampler: jacta.planner.core.action_sampler.ActionSampler, logger: jacta.planner.core.logger.Logger, params: jacta.planner.core.parameter_container.ParameterContainer, callback: Optional[Callable] = None, callback_period: Optional[int] = None)


   .. py:method:: reset() -> None


   .. py:method:: node_selection(search_indices: torch.IntTensor) -> torch.IntTensor

      
      Selects a collection of nodes. Nodes a ranked either by reward or scaled distance to goal.
      Then nodes are selected according to the Pareto distribution.

      :param search_indices: the indices of the searches to select nodes for

   .. py:method:: get_start_actions(node_ids: torch.IntTensor) -> torch.FloatTensor


   .. py:method:: get_end_actions(node_ids: torch.IntTensor, relative_actions: torch.FloatTensor, action_type: Optional[jacta.planner.core.types.ActionType]) -> torch.FloatTensor


   .. py:method:: node_extension(node_ids: torch.IntTensor, relative_actions: torch.FloatTensor, num_action_steps: int, action_type: Optional[jacta.planner.core.types.ActionType] = None) -> Tuple[torch.IntTensor, float, bool]

      
      Chooses a node to extend to based on the current node and action sampler.

      :param node_ids: the id sof the nodes to extend from with the actions
      :param actions: control vectors of size (nu,)
      :param num_action_steps: the number of steps. Must be the same for all extensions to perform parallel rollout

   .. py:method:: node_pruning(paths_ids: torch.IntTensor) -> torch.IntTensor

      
      Finds the best node in path_ids and removes all nodes after the best node

   .. py:method:: node_replacement(node_ids: torch.IntTensor, paths_ids: torch.IntTensor, best_indices: torch.IntTensor) -> Tuple[int, bool]

      
      Tries to replace the path from predecessor_node to node with a direct_node from predecessor_node

   .. py:method:: percentage_range(start: int, stop: int) -> range


   .. py:method:: get_progress_info(iteration: int, num_steps: int, print_percentage: bool = False, verbose: bool = False) -> torch.FloatTensor


   .. py:method:: callback_and_progress_check(iteration: int, num_steps: int, change_goal: bool = False, verbose: bool = False) -> torch.BoolTensor

      
      Calls the search callback. Returns True if goal reached


.. py:class:: SingleGoalWorker(plant: jacta.planner.dynamics.simulator_plant.SimulatorPlant, graph: jacta.planner.core.graph.Graph, action_sampler: jacta.planner.core.action_sampler.ActionSampler, logger: jacta.planner.core.logger.Logger, params: jacta.planner.core.parameter_container.ParameterContainer, callback: Optional[Callable] = None, callback_period: Optional[int] = None)


   Bases: :py:obj:`GraphWorker`

   .. py:method:: work(verbose: bool = False) -> bool

      
      Tries to find a path to a single goal.


.. py:class:: ParallelGoalsWorker(*args: Tuple, **kwargs: dict)


   Bases: :py:obj:`GraphWorker`

   .. py:method:: try_to_reallocate_workers(worker_reset_mask: torch.BoolTensor) -> None


   .. py:method:: update_extension_lengths(search_reset_mask: torch.BoolTensor) -> None


   .. py:method:: reset_finished_workers() -> None


   .. py:method:: update_pareto_parameters(node_ids: torch.IntTensor, new_node_ids: torch.IntTensor) -> None


   .. py:method:: work(verbose: bool = False) -> bool

      
      Tries to find a path to a single goal.


.. py:class:: CommonGoalWorkerInterface(*args: Tuple, **kwargs: dict)



.. py:class:: RelatedGoalWorker(*args: Tuple, **kwargs: dict)


   Bases: :py:obj:`CommonGoalWorkerInterface`

   .. py:method:: work(verbose: bool = False) -> bool

      
      Tries to find paths to goals sampled around the actual goal.


.. py:class:: ExplorerWorker(*args: Tuple, **kwargs: dict)


   Bases: :py:obj:`CommonGoalWorkerInterface`

   .. py:method:: work(verbose: bool = False) -> bool

      
      Tries to find paths to randomly sampled goals


.. py:class:: RolloutWorker(plant: jacta.planner.dynamics.simulator_plant.SimulatorPlant, graph: jacta.planner.core.graph.Graph, action_sampler: jacta.planner.core.action_sampler.ActionSampler, logger: jacta.planner.core.logger.Logger, params: jacta.planner.core.parameter_container.ParameterContainer, callback: Optional[Callable] = None, callback_period: Optional[int] = None)


   Bases: :py:obj:`GraphWorker`

   .. py:method:: work(verbose: bool = False) -> bool

      
      Always extends the last node.


.. py:function:: inspect_action_type(graph_worker: GraphWorker, action_type: jacta.planner.core.types.ActionType, node_ids: torch.IntTensor | None = None, num_action_steps: int = 100) -> torch.FloatTensor

   
   Inspection tool for a specific action type. This rollout the dynamics of the system
   assuming that we always select the same action_type.

