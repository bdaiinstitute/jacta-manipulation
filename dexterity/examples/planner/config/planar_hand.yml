# Copyright (c) 2023 Boston Dynamics AI Institute LLC. All rights reserved.

model_filename: dexterity/models/xml/scenes/legacy/planar_hand.xml

start:
  state: ([0, 0.25, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
goal:
  state: ([0.10, 0.3, -1 * np.pi, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])

action:
  bound_lower: ([-np.pi / 2, -2.4, 0, 0])
  bound_upper: ([0, 0, np.pi / 2, 2.4])
  range: torch.ones_like(self.action_bound_lower) * 6

reward:
  distance_scaling: torch.cat((torch.tensor([1, 1, 1 / (2 * np.pi)]), torch.zeros(4), torch.ones(3)*0.01, torch.zeros(4)))


vis: # TODO is this retiring?
  filename: dexterity/models/xml/scenes/legacy/planar_hand.yml
  scale: ([1, -0.5 / np.pi, 1])
  indices: ([0, 2, 1])

planner:
  single_goal:
    steps_per_goal: 500
    parallel_extensions: 5
    eigenspaces_file: "planar.yml"
  multi_goal:
    intermediate_pruning: False
    intermediate_replacement: False
    num_sub_goals: 20
    steps_per_goal: 10
    start:
      state: ([0, 0.2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
