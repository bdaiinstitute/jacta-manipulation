# Copyright (c) 2023 Boston Dynamics AI Institute LLC. All rights reserved.

model_filename: dexterity/models/xml/scenes/legacy/floating_hand.xml

action:
  bound_lower: ([-2, 0.2, -np.pi / 2, -2.4, 0.0, 0.0])
  bound_upper: ([+2, +2, 0.0, 0.0, np.pi / 2, 2.4])
  range: ([2, 2, 6, 12, 6, 12])

reward:
  distance_scaling: torch.cat((torch.tensor([1, 1, 1 / (2 * np.pi)]), torch.zeros(6), torch.zeros(3), torch.zeros(6)))

start:
  state: ([0, 0.15, 0, 0, 0.5, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
goal:
  state: ([0.5, 0.6, +2 * np.pi, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])

vis:
  filename: "floating_hand.yml"
  indices: ([0, 2, 1])
  scale: ([1, -0.5 / np.pi, 1])

planner:
  single_goal:
    steps_per_goal: 1000

  multi_goal:
    steps_per_goal: 10
    num_sub_goals: 20
    intermediate_pruning: False
    intermediate_replacement: False

  exploration:
    start:
      bound_lower: ([-0.5, 0.15, 0, 0, -0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
      bound_upper: ([0.5, 0.25, 0, 0, 0.1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])

    goal:
      state: ([0.25, 0.3, +1 * np.pi, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
      bound_lower: ([-0.5, 0.15, 0 * np.pi, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])
      bound_upper: ([0.5, 0.6, 2 * np.pi, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0])

    reward:
      distance_scaling: torch.cat((torch.tensor([1, 1, 1 / (2 * np.pi)]), torch.zeros(6), torch.ones(3) * 0.1, torch.zeros(6)))
    termination_distance: 0.0
    intermediate_pruning: False
    intermediate_replacement: False
    num_sub_goals: 50
    steps_per_goal: 30
    num_parallel_searches: 5
    callback_period: 5
