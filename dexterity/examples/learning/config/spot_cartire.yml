# Copyright (c) 2023 Boston Dynamics AI Institute LLC. All rights reserved.

model_filename: dexterity/models/xml/scenes/legacy/spot_cartire.xml

action:
  time_step: 1/200.0
  bound_lower: ([-0.785398, -0.898845, -2.7929] * 4 + [0.7, 0.05, 2.0, 0.1, 1.5, 0.1, -0.05])
  bound_upper: ([0.785398, 2.295108, -0.2471] * 4 + [0.7, 0.05, 2.0, 0.1, 1.5, 0.1, -0.05])
  start_mode: ActionMode.RELATIVE_TO_CURRENT_STATE
  end_mode: ActionMode.ABSOLUTE_ACTION
  range: ([0.4, 0.4, 0.4] * 4 + [0.2, 0.4, 0.5, 0.6, 0.7, 0.7, 0.7])
  types: ([AT.RANGED, AT.PROXIMITY, AT.CONTINUATION, AT.GOAL])
  distribution: ([1, 1, 1, 1])

control_type: ControlType.ZERO_ORDER_HOLD

start:
  state:
    - ([0,  0, 0.51] + [1, 0, 0, 0])
    - ([+0.1, 0.9, -1.5])
    - ([-0.1, 0.9, -1.5])
    - ([+0.1, 1.1, -1.5])
    - ([-0.1, 1.1, -1.5])
    - ([0, -0.9, 1.8, 0, -0.9, 0, -1.54])
    - ([2.0,  0, 0.275] + [1, 0, 0, 0])
    - ([0.0] * 31)
goal:
  state:
    - ([0,  0, 0.51] + [1, 0, 0, 0])
    - ([+0.1, 0.9, -1.5])
    - ([-0.1, 0.9, -1.5])
    - ([+0.1, 1.1, -1.5])
    - ([-0.1, 1.1, -1.5])
    - ([0, -0.9, 1.8, 0, -0.9, 0, -1.54])
    - ([4.0,  0.5, 0.275] + [1, 0, 0, 0])
    # - ([-2.0,  0.0, 0.275] + [1, 0, 0, 0])
    # - ([2.0,  3.0, 0.275] + [1, 0, 0, 1])
    - ([0.0] * 31)

reward:
  distance_scaling:
    - ([0] * 25 + [1] * 3 + [0] * 3 + [0] * 31)
  proximity_scaling: 0.1
