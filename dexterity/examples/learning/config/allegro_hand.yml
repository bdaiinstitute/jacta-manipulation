# Copyright (c) 2023 Boston Dynamics AI Institute LLC. All rights reserved.

model_filename: dexterity/models/xml/scenes/legacy/allegro_scene_tilt_wrist.xml

vis:
  indices: ([0, 1, 6])
  scale: ([10, 10, 1])

action:
  bound_lower: ([-0.15] * 2 + [-0.47, -0.196, -0.174, -0.227] * 3 + [0.263, -0.105, -0.189, -0.162])
  bound_upper: ([ 0.15] * 2 + [+0.47, +1.610, +1.709, +1.618] * 3 + [1.396, +1.163, +1.644, +1.719])
  range: ([0.5] * 2 + [1.57] * 16)
  types: "[AT.RANGED, AT.PROXIMITY, AT.CONTINUATION, AT.GOAL]"
  distribution: ([1, 2, 3, 2])

reward:
  distance_scaling: ([100, 100, 100, 1, 1, 10] + [0] * 18 + [10, 10, 10, 0.1, 0.1, 0.1] + [0] * 18)
  proximity_scaling: 0.01
  reachability_scaling: 0.01

start:
  state:       ([   0.0,    0.0, 0.042, 1, 0, 0, 0] + [0,0, 0,0,0.8,0.8, 0,0,0.8,0.8, 0,0,0.8,0.8, 0,1.57,0.8,0.8] + [0] * 24)
  bound_lower: ([-0.025, -0.025, 0.042, 1, 0, 0, 0] + [0,0, 0,0,0.8,0.8, 0,0,0.8,0.8, 0,0,0.8,0.8, 0,0.8,0.8,0.8] + [0] * 24)
  bound_upper: ([ 0.025,  0.025, 0.042, 1, 0, 0, 0] + [0,0, 0,0,0.8,0.8, 0,0,0.8,0.8, 0,0,0.8,0.8, 0,0.8,0.8,0.8] + [0] * 24)
goal:
  # task 0 - rotate 180 degrees along z axis
  state:       ([   0.0,    0.0, 0.042,               0, 0, 0,               1] + [0] * 18 + [0] * 24)
  bound_lower: ([-0.025, -0.025, 0.042,               0, 0, 0, np.sin(np.pi/4)] + [0] * 18 + [0] * 24)
  bound_upper: ([ 0.025,  0.025, 0.042, np.cos(np.pi/4), 0, 0,               1] + [0] * 18 + [0] * 24)

learner:
  early_stop: 1.0
  trajectory_length: 50
  use_sparse_reward: True
  final_success_distance: 0.2
  stop_converged_injection: False
  max_planner_experience_share: 0.0

intermediate_pruning: False
num_sub_goals: 30
steps_per_goal: 30
goal_bias: 0.0
termination_distance: 0.0
max_main_nodes: 50000
action_time_step: 0.4
action_steps_max: 3

seed: 0
